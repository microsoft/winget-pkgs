# Created using wingetcreate
# yaml-language-server: =https://aka.ms/winget-manifest.defaultLocale.1.6.0.schema.json
PackageIdentifier: imonoonoko.BitLlama
PackageVersion: 0.15.0
PackageLocale: en-US
Publisher: imonoonoko
PublisherUrl: https://github.com/imonoonoko
PackageName: BitLlama
PackageUrl: https://github.com/imonoonoko/Bit-TTT-Engine
License: MIT
LicenseUrl: https://github.com/imonoonoko/Bit-TTT-Engine/blob/main/LICENSE
ShortDescription: Pure Rust LLM inference engine with 1.58-bit ternary support and Test-Time Training
Description: |-
  BitLlama is a Pure Rust LLM inference engine featuring 1.58-bit ternary quantization,
  Test-Time Training (TTT), Soul learning system, MCP server/client, and private RAG.
  Supports Llama, Gemma, Mistral, Qwen, and BitNet models.
  OpenAI-compatible API server included.
Tags:
  - ai
  - cli
  - inference
  - llm
  - machine-learning
  - rust
ReleaseNotesUrl: https://github.com/imonoonoko/Bit-TTT-Engine/releases/tag/v0.15.0
ManifestType: defaultLocale
ManifestVersion: 1.6.0
