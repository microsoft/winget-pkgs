# Created with WinGet Updater using komac v2.12.1
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: TabbyML.Tabby
PackageVersion: 0.30.2
PackageLocale: en-US
Publisher: TabbyML
PublisherUrl: https://tabby.tabbyml.com/
PublisherSupportUrl: https://github.com/TabbyML/tabby/issues
Author: TabbyML
PackageName: Tabby
PackageUrl: https://tabby.tabbyml.com/
License: Apache 2.0
LicenseUrl: https://github.com/TabbyML/tabby/blob/HEAD/LICENSE
Copyright: Copyright (c) TabbyML, Inc.
CopyrightUrl: https://github.com/TabbyML/tabby/blob/main/LICENSE
ShortDescription: Self-hosted AI coding assistant
Description: Tabby is a self-hosted AI coding assistant, offering an open-source and on-premises alternative to GitHub Copilot.
Moniker: tabby
Tags:
- ai
- codegen
- coding-assistant
- coding-language
- developer-experience
- developer-tools
- gen-ai
- ide
- llms
ReleaseNotes: |-
  ‚ö†Ô∏è Notice
  - This is a patch release, please also check the full release note for 0.30.
  üß∞ Fixed and Improvements
  - Use 0.7.3 sqlx to avoid database pool timeout. #4328
  - Bump llama.cpp to b6047. #4330
  - Expose the Flash Attention LLAMA flag as an environment variable. #4323
ReleaseNotesUrl: https://github.com/TabbyML/tabby/releases/tag/v0.30.2
ManifestType: defaultLocale
ManifestVersion: 1.10.0
