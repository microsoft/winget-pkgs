# Created with YamlCreate.ps1 v2.4.1 Dumplings Mod $debug=QUSU.CRLF.7-4-5.Win32NT
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.6.0.schema.json

PackageIdentifier: MintplexLabs.AnythingLLM
PackageVersion: 1.6.9
PackageLocale: en-US
Publisher: Mintplex Labs Inc
PublisherUrl: https://anythingllm.com/
PublisherSupportUrl: https://docs.anythingllm.com/support
# PrivacyUrl:
Author: Mintplex Labs Inc.
PackageName: AnythingLLM
PackageUrl: https://anythingllm.com/download
License: MIT
LicenseUrl: https://github.com/Mintplex-Labs/anything-llm/blob/HEAD/LICENSE
Copyright: Copyright (c) Mintplex Labs Inc.
# CopyrightUrl:
ShortDescription: The all-in-one AI app you were looking for. Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating set up required.
Description: AnythingLLM is a full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.
# Moniker:
Tags:
- ai
- chatbot
- chatgpt
- claude
- gemini
- gpt
- large-language-model
- llm
- lmstudio
- mistral
- ollama
- rag
ReleaseNotes: |-
  What's New:

  AMD GPU Support + More

  Our internal Ollama provider was bumped to the latest version (0.3.14) which includes support for AMD GPUs, as well as other improvements.
  For Windows, we install the additional support files during the installation process automatically. For MacOS, there is nothing to do.
  Import any Ollama Model Tag or Hugging Face Model

  You can now import any Ollama model tag or Hugging Face model into AnythingLLM using the default Ollama provider. Simply enter the tag or URL and hit import. This allows you to use models that are not explicitly listed in the UI.
  Just paste in the ollama run command and hit import!
  Pulling from Ollama.com (opens in a new tab) example: ollama run mistral-nemo
  Pulling from Hugging Face (opens in a new tab) example: ollama run hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF
  Computer Use (Anthropic AI)

  AnythingLLM can now leverage the new Anthropic AI Computer Use models.
  This is an experimental feature (opens in a new tab) and must be explicitly enabled in your system settings.
  Find-in-page support for workspace chat

  You can now find specific text within the workspace chat window. Simply press Ctrl+F to open the finder input at the top-right of the chat window.
  Other Improvements:

  -
    Added NovitaAI (opens in a new tab) as a supported LLM Provider
  -
    Improved document metadata for embedding/RAG results
  -
    Added Session Token support for AWS BedRock inference
  -
    Added API docs update
  -
    Added API Limit/orderBy for workspace/chats endpoint
  -
    Added support for INO filetype
  Bug Fixes:

  -
    Patch restriction where localhost address web scraping was blocked.
  -
    Patch bad reference for Ephemeral agent invocation
  -
    Fixed issue where files with non-latin characters were not being respected when uploaded via API
  What's Next:

  - Community Hub for Agent skills, workspace sharing, and more. Pull Request #2555 (opens in a new tab)
  - True dark mode and light mode UI Pull Request #2481 (opens in a new tab)
ReleaseNotesUrl: https://docs.anythingllm.com/changelog/v1.6.9
# PurchaseUrl:
# InstallationNotes:
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://docs.anythingllm.com/
ManifestType: defaultLocale
ManifestVersion: 1.6.0
