# Created with YamlCreate.ps1 v2.4.1 Dumplings Mod $debug=QUSU.CRLF.7-4-5.Win32NT
# yaml-language-server: $schema=https://aka.ms/winget-manifest.locale.1.6.0.schema.json

PackageIdentifier: Mozilla.llamafile
PackageVersion: 0.8.16
PackageLocale: zh-CN
Publisher: Mozilla Ocho
PublisherUrl: https://github.com/Mozilla-Ocho
PublisherSupportUrl: https://github.com/Mozilla-Ocho/llamafile/issues
# PrivacyUrl:
# Author:
PackageName: llamafile
PackageUrl: https://github.com/Mozilla-Ocho/llamafile
License: Apache-2.0
LicenseUrl: https://github.com/Mozilla-Ocho/llamafile/blob/HEAD/LICENSE
Copyright: Copyright 2024 Mozilla Foundation
# CopyrightUrl:
ShortDescription: llamafile 可让您使用单个文件分发和运行 LLM。
Description: |-
  llamafile 可让您使用单个文件分发和运行 LLM。
  我们的目标是让开发者和最终用户都能更方便地使用开放 LLM。为此，我们将 llama.cpp 与 Cosmopolitan Libc 结合成一个框架，将 LLM 化繁为简压缩至单一的可执行文件 (称作“llamafile”)，无需安装即可在大多数计算机本地运行。
# Moniker:
Tags:
- llama
- llm
- 人工智能
- 大语言模型
# ReleaseNotes:
ReleaseNotesUrl: https://github.com/Mozilla-Ocho/llamafile/releases/tag/0.8.16
# PurchaseUrl:
# InstallationNotes:
# Documentations:
ManifestType: locale
ManifestVersion: 1.6.0
