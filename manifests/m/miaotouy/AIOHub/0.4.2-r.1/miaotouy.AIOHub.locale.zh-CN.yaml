# Created with YamlCreate.ps1 v2.5.0 $debug=NVS1.CRLF.7-5-4.Win32NT
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: miaotouy.AIOHub
PackageVersion: 0.4.2-r.1
PackageLocale: zh-CN
Publisher: mty
PublisherUrl: https://github.com/miaotouy
PublisherSupportUrl: https://github.com/miaotouy/aio-hub/issues
# PrivacyUrl:
# Author:
PackageName: AIO Hub
PackageUrl: https://github.com/miaotouy/aio-hub
License: MIT
LicenseUrl: https://github.com/miaotouy/aio-hub/blob/HEAD/LICENSE
Copyright: Copyright (c) 2025 miaotouy
# CopyrightUrl:
ShortDescription: AI 平台应用，提供多种实用的开发和日常工具，以及高可控性的 LLM 交互。
Description: |-
  一个基于 Tauri + Vue 3 + TypeScript 开发的桌面端枢纽应用，提供多种实用的开发和日常工具。

  🌟 旗舰功能：LLM 智能对话
  AIO Hub 的聊天功能是一个专为复杂任务和深度探索而设计的、高度可定制的对话式 AI 工作空间。
  🌐 开放的模型生态 (Open Model Ecosystem)
  无缝集成，灵活扩展。
  - 多服务商支持：原生支持 OpenAI, Anthropic (Claude), Google (Gemini), Cohere, DeepSeek 等多家主流 LLM 供应商。并且通过兼容 OpenAI API 的接口（如 Ollama, LM Studio, Llama.cpp），轻松接入和管理本地运行的语言模型。
  - 自定义端点：支持为所有已集成的服务类型（如 OpenAI, Claude, Gemini 等）添加自定义 API 端点，具备极高的可扩展性。
  - 可视化模型管理：在设置中可以集中管理所有模型的元数据，定义其能力（如视觉、工具使用），并在工具中根据任务需求（如“需要视觉能力”）进行智能筛选。
  🌳 双视图对话管理 (Dual-View Conversation Management)
  在传统的线性列表与创新的非线性图谱之间自由切换，满足不同场景的需求。
  - 传统线性视图 (Linear List View)
    - 极致性能：基于 @tanstack/vue-virtual 实现虚拟滚动，轻松处理包含数千条消息的超长会话，始终保持流畅。
    - 熟悉的体验：经典的自上而下消息流，符合直觉，上手零成本。
    - 消息导航器：配备了快速跳转（到顶部/底部）和新消息提示功能。
    - 精细化控制：消息的悬浮工具栏支持复制、编辑、重新生成、创建分支、上下文分析、禁用消息等多种功能，实现对会话的深度控制。
  - 非线性对话图谱 (Non-linear Conversation Graph)
    - 无限画布：由 Vue Flow + D3.js 驱动，将对话历史呈现为可交互的树状网络。
    - 双布局引擎：提供清晰层级的树状布局和动态物理模拟的力导向布局，并支持一键切换。
    - 高级节点操作：启用/禁用分支、查看详情、复制内容、删除子树。
    - 自由的结构重组：通过拖拽连接线“嫁接”分支，自由重组对话流，所有结构操作均支持撤销/重做。
    - 可视化辅助：内置小地图、缩放/平移控件和活动分支高亮，在复杂的对话网络中也能轻松导航。
  🛠️ 专业级上下文工程 (Prompt Engineering)
  完全掌控发送给模型的每一个 Token。
  - 上下文分析器：开发者级调试工具。清晰地查看最终发送给 LLM 的完整 Prompt、历史消息、Token 消耗和原始请求体。
  - 高级上下文注入：引入了声明式的消息注入策略，可以精确控制预设消息在上下文中的位置（如“倒数第二条”或“某个锚点之前”），并支持导入 SillyTavern 角色卡和预设，无缝复用社区资源。
  - 宏系统 (Macro System): 在 Prompt 中使用 {{user}}, {{time}}, {{random::...}} 等动态宏，构建强大的自动化工作流。
  - 智能体 (Agents): 智能体的核心是预设消息序列，它允许你将一系列 System, User, Assistant 消息（包括特殊的“用户档案”和“聊天历史”占位符）组合成一个可复用的模板。通过拖拽调整顺序、启用/禁用特定消息，可以构建出高度定制化的对话开场或上下文，并支持导入/导出和社区分享。
  - 动态智能体切换：与传统聊天应用中“一次会话绑定一个助手”的模式不同，AIO Hub 将会话与智能体彻底解耦。你可以在同一段对话中随时切换智能体，让“代码专家”帮你写代码，再无缝切换到“文档专家”帮你写注释，使对话能够围绕“任务”本身而非某个固定的“助手”展开。
  - 用户档案 (Personas): 预设多个用户身份（如“高级架构师”、“代码审查员”），随时切换，让 AI 更懂你的角色和需求。
  🖼️ 多模态交互 (Multi-modal Interaction)
  - 文件上传与引用：拖拽或粘贴图片、PDF、TXT 等文件到聊天窗口。文件将被资产管理器统一处理，方便在聊天中引用，以实现“总结这份 PDF”、“分析这张图表”等高级功能。
  - 视觉模型支持：完美配合 Gemini, Claude, GPT-5, Qwen-VL 等多模态模型的视觉识别能力。

  ✨ 核心亮点
  🖼️ 自由窗口管理
  打破传统布局限制。
  - 组件级分离：不仅是工具，连聊天输入框、对话区域都可以被拖拽成为独立的浮动窗口。
  - 状态同步：所有分离窗口共享同一个状态源，在一个窗口操作，所有窗口实时更新。
  - 记忆功能：自动记住所有窗口的位置和大小。
  🎨 极致视觉体验
  - 原生特效：支持 Windows Mica / Acrylic 和 macOS Vibrancy 毛玻璃特效。
  - 动态壁纸：支持视频/图片轮播壁纸，配合 CSS 混合模式 (Blend Modes)，打造沉浸式工作台。
  - 深度定制：内置 CSS 编辑器，支持实时修改应用样式的每一个细节。
  🧩 强大的插件系统
  - JavaScript 插件：轻量级 UI 扩展，即写即用。
  - Native 插件 (Rust): 高性能后端扩展，通过 DLL 动态加载。
  - Sidecar 插件：支持任意语言编写的独立进程插件。

  🚀 效率工具集
  📊 Git 仓库分析器 (Git Analyzer)
  基于 Rust git2-rs 的高性能分析工具
  - 无依赖：不依赖系统 Git 命令，直接读取 .git 数据库，速度极快。
  - 流式分析：采用流式传输技术，秒开大型仓库，实时渲染提交图表。
  - 多维可视化：贡献者热力图、提交频率图、代码行数统计。
  👁️ 智能 OCR (Smart OCR)
  多引擎融合的文字识别方案
  - 多引擎切换：支持 VLM (GPT-4o)、Windows Native (离线快)、Tesseract.js (纯前端)。
  - 智能切图：独创的长图切片算法，自动识别空白区域切割长截图，大幅提升识别率。
  - 批量处理：支持多图并发识别和结果导出。
  📦 资产管理器 (Asset Manager)
  应用级的资源中心
  - 统一索引：集中管理所有工具产生的图片、文档和媒体文件。
  - 自动去重：基于内容哈希 (SHA-256) 的自动去重机制，节省存储空间。
  - 高性能：Rust 后端驱动的快速索引和筛选，支持无限滚动。
  🎨 正则表达式应用器 (Regex Applier)
  双引擎正则处理工具
  - 实时预览：前端 JS 引擎提供毫秒级的输入反馈。
  - 批量处理：后端 Rust 引擎处理大规模文件修改，性能强劲。
  - 规则链：将多个正则替换组合成一条处理流水线 (Pipeline)。
  📝 富文本渲染引擎 (Rich Text Renderer)
  专为 LLM 流式输出打造的高性能渲染方案
  - 零闪烁流式渲染：采用增量 Diff 算法和 Patch 系统，完美解决流式输出时的抖动问题，带来打字机般的丝滑体验。
  - 深度混合排版：自研解析器，完美支持 Markdown 与任意深度 HTML 标签的混合嵌套。
  - 丰富的交互组件：
    - 代码块：集成 Monaco Editor，提供专业级的高亮、折叠和字体控制。
    - 思维链：原生支持 <think> 标签，以可折叠的动态组件展示 LLM 的思考过程。
    - 图表与公式：内置 Mermaid 图表（支持缩放/独立窗口）和 KaTeX 数学公式渲染。
  - MD 样式编辑器 (Style Editor):
    - 所见即所得：针对标题、段落、引用、代码等每一种 Markdown 元素提供独立的实时预览面板。
    - 全掌控：可精细调整字体、颜色、边距等 CSS 属性，打造独一无二的阅读体验。
    - 灵活性：支持一键启用/禁用自定义样式，或重置为系统默认，随心切换。
  🛠️ 更多实用工具
  - JSON 格式化：智能格式化和美化 JSON 数据，支持语法高亮和错误提示，可一键发送至聊天窗口进行分析。
  - Token 计算器：估算文本 Token 数，支持多种分词模型。
  - 颜色提取器：屏幕取色、图片色板分析。
  - 文本差异对比：基于 Monaco Editor 的专业级 Diff 工具。
  - 目录树生成：生成项目结构树，支持 .gitignore 过滤。
  - 以及更多工具……
# Moniker:
# Tags:
ReleaseNotes: |-
  AIO Hub v0.4.2-r.1 🎉 新版本发布
  🌟 核心功能 (Core Features)
  🧩 高级上下文注入策略 (Advanced Context Injection Strategy)
  我们重构了 LLM 上下文的构建引擎，引入了一套声明式的消息注入策略。现在，你可以精确控制每一条预设消息在最终发送给模型的上下文中的位置和顺序。
  - 深度注入 (depth): 将消息插入到距离对话历史末尾 n 层的位置。
  - 锚点注入 (anchorTarget): 将消息精准地插入到系统锚点（如 chat_history, user_profile）的前面或后面。
  - 顺序控制 (order): 通过优先级数字，决定在同一点注入多条消息时的最终顺序。
  - UI 集成：在智能体预设编辑器中，可以为每条消息单独配置注入策略。
  🍻 SillyTavern 兼容性与导入 (SillyTavern Compatibility & Import)
  为了方便用户迁移和复用社区资源，我们正式支持了 SillyTavern 的角色卡和预设导入功能。
  - 角色卡导入：支持直接导入 .json 格式或内嵌数据的 .png 角色卡文件，角色头像和设定会被自动解析并创建为新的 AIO 智能体。
  - 预设文件导入：支持在智能体预设中追加导入 SillyTavern 的提示词预设文件（.json / .yaml），系统会自动解析其结构，并提示用户是否应用其中的模型参数。
  ⚙️ 架构重构与优化 (Refactoring & Improvements)
  - 上下文构建模块化：复杂的上下文构建逻辑被拆分为独立的、可维护的模块 (useContextInjection, useContextLimiter, useContextPreview)，提升了代码的可维护性。
  - 智能体复制增强：
    - 复制智能体时，现在会自动处理其私有的头像文件，确保副本拥有独立的头像资产。
    - 优化了命名逻辑，复制后的智能体 displayName 会自动添加编号以保证唯一性。
  - 状态管理优化：上下文的 Token 和字符统计逻辑被集中到 llm-chat Store 中统一管理，避免了在多个组件中重复计算。
  变更内容
  查看完整的 Changelog
ReleaseNotesUrl: https://github.com/miaotouy/aio-hub/releases/tag/v0.4.2-r.1
# PurchaseUrl:
# InstallationNotes:
# Documentations:
ManifestType: defaultLocale
ManifestVersion: 1.10.0
