# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.locale.1.9.0.schema.json

PackageIdentifier: nekomeowww.OllamaOperator
PackageVersion: 0.10.5
PackageLocale: zh-CN
PackageUrl: https://ollama-operator.ayaka.io/pages/zh-CN/
ShortDescription: "一个在 Kubernetes 上让部署和运行大型语言模型变得轻松简单的 Operator，由 Ollama 强力驱动 \U0001F42B"
Description: |-
  即便 Ollama 已经是一个强大的用于在本地运行大型语言模型的工具，并且 CLI 的用户体验与使用 Docker CLI 相同，但可惜的是，目前还无法在 Kubernetes 上直接复刻相同的用户体验，特别是同一集群上在运行多个模型时，涉及大量资源和配置。
  这就是 Ollama Operator 发挥作用的地方：
  - 在您的 Kubernetes 集群上安装 operator
  - 应用所需的 CRDs
  - 创建您的模型
  - 等待模型被获取和加载，就是这样！
  多亏了 lama.cpp 的出色工作，不再担心 Python 环境、CUDA 驱动程序。 通往大型语言模型、AIGC、本地化代理、🦜🔗 Langchain 等的旅程只需几步之遥！
Tags:
- docker
- k8s
- kubernetes
- ollama
- 容器
- 集群
ReleaseNotesUrl: https://github.com/nekomeowww/ollama-operator/releases/tag/v0.10.5
ManifestType: locale
ManifestVersion: 1.9.0
