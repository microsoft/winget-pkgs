# Created with komac v2.2.1
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.6.0.schema.json

PackageIdentifier: nomic.gpt4all
PackageVersion: 2.8.0
PackageLocale: en-US
Publisher: Nomic
PublisherUrl: https://github.com/nomic-ai
PublisherSupportUrl: https://github.com/nomic-ai/gpt4all/issues
PackageName: GPT4All
PackageUrl: https://github.com/nomic-ai/gpt4all
License: MIT
LicenseUrl: https://github.com/nomic-ai/gpt4all/blob/HEAD/LICENSE.txt
ShortDescription: GPT4All is a GUI application for loading and interacting with Generative AI models
Tags:
- llm-inference
Agreements:
- AgreementLabel: End User License Agreement (EULA)
  AgreementUrl: https://github.com/nomic-ai/gpt4all/blob/main/LICENSE.txt
ReleaseNotes: |-
  What's New
  - Context Menu: Replace "Select All" on message with "Copy Message" (#2324)
  - Context Menu: Hide Copy/Cut when nothing is selected (#2324)
  - Improve speed of context switch after quickly switching between several chats (#2343)
  - New Chat: Always switch to the new chat when the button is clicked (#2330)
  - New Chat: Always scroll to the top of the list when the button is clicked (#2330)
  - Update to latest llama.cpp as of May 9, 2024 (#2310)
  - Add support for the llama.cpp CUDA backend (#2310, #2357)
      - Nomic Vulkan is still used by default, but CUDA devices can now be selected in Settings
      - When in use: Greatly improved prompt processing and generation speed on some devices
      - When in use: GPU support for Q5_0, Q5_1, Q8_0, K-quants, I-quants, and Mixtral
  - Add support for InternLM models (#2310)
  Fixes
  - Do not allow sending a message while the LLM is responding (#2323)
  - Fix poor quality of generated chat titles with many models (#2322)
  - Set the window icon correctly on Windows (#2321)
  - Fix a few memory leaks (#2328, #2348, #2310)
  - Do not crash if a model file has no architecture key (#2346)
  - Fix several instances of model loading progress displaying incorrectly (#2337, #2343)
  - New Chat: Fix the new chat being scrolled above the top of the list on startup (#2330)
  - macOS: Show a "Metal" device option, and actually use the CPU when "CPU" is selected (#2310)
  - Remove unsupported Mamba, Persimmon, and PLaMo models from the whitelist (#2310)
  - Fix GPT4All.desktop being created by offline installers on macOS (#2361)
  Full Changelog: https://github.com/nomic-ai/gpt4all/compare/v2.7.5...v2.8.0
ReleaseNotesUrl: https://github.com/nomic-ai/gpt4all/releases/tag/v2.8.0
Documentations:
- DocumentUrl: https://docs.gpt4all.io/
ManifestType: defaultLocale
ManifestVersion: 1.6.0
