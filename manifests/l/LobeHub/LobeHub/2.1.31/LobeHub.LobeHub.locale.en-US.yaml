# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.12.0.schema.json

PackageIdentifier: LobeHub.LobeHub
PackageVersion: 2.1.31
PackageLocale: en-US
Publisher: LobeHub
PublisherUrl: https://lobehub.com/
PublisherSupportUrl: https://github.com/lobehub/lobe-chat/issues
PrivacyUrl: https://lobehub.com/privacy
Author: LobeHub LLC
PackageName: LobeHub-Beta
PackageUrl: https://github.com/lobehub/lobe-chat
License: Apache-2.0
LicenseUrl: https://github.com/lobehub/lobe-chat/blob/HEAD/LICENSE
Copyright: Copyright (c) 2026/06/17 - current LobeHub LLC. All rights reserved.
CopyrightUrl: https://lobehub.com/terms
ShortDescription: An open-source, modern-design AI chat framework. Supports Multi AI Providers (OpenAI / Claude 4 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG), Multi-Modals (Plugins/Artifacts) and Thinking.
Tags:
- ai
- chatbot
- chatgpt
- claude
- deepseek
- doubao
- gemini
- kimi
- large-language-model
- llama
- llm
- mistral
- ollama
- qwen
- rag
ReleaseNotes: |-
  This release was automatically published from PR #11708.
  Changes
  See PR description: https://github.com/lobehub/lobehub/pull/11708
  Commit Message
  ğŸ’» Change Type
  - 
    âœ¨ feat
  - 
    ğŸ› fix
  - 
    â™»ï¸ refactor
  - 
    ğŸ’„ style
  - 
    ğŸ‘· build
  - 
    âš¡ï¸ perf
  - 
    âœ… test
  - 
    ğŸ“ docs
  - 
    ğŸ”¨ chore
  ğŸ”— Related Issue
  Closes #10346
  ğŸ”€ Description of Change
  1. æ›´æ–°çš„æ–‡ç”Ÿå›¾ï¼Œå›¾ç”Ÿå›¾æ¨¡å‹åˆ—è¡¨ï¼Œz-image wan2.5 wan2.6 qwen-image-plus/max qwen-image-edit-plus/max
  2. æ–°å¢ image2image endpointï¼Œä¸ºè€ç‰ˆæœ¬å›¾ç”Ÿå›¾æ¨¡å‹è¿›è¡Œå…¼å®¹
  3. é»˜è®¤ä½¿ç”¨ multimodal-generation endpointï¼ˆæ–°æ¨¡å‹ç›®å‰è°ƒç ”ä¸‹æ¥éƒ½æ˜¯ç”¨è¿™ä¸ªäº†ï¼ŒåŒæ—¶æ”¯æŒå›¾ç”Ÿå›¾å’Œæ–‡ç”Ÿå›¾ï¼‰
  4. æ”¯æŒå¤šåŒºåŸŸ Dashscope URLï¼Œè·Ÿéš baseUrl å‚æ•°ï¼Œè‡ªåŠ¨åˆ‡åˆ† /compatible-mode/v1 é»˜è®¤åŒ—äº¬åŒºåŸŸ
     åŒ—äº¬ https://dashscope.aliyuncs.com
     æ–°åŠ å¡ https://dashscope-intl.aliyuncs.com
     å¼—å‰å°¼äºš https://dashscope-us.aliyuncs.com
  Endpoint

  multimodal-generation
  text2image
  ğŸ§ª How to Test
  - 
    Tested locally
  - 
    Added/updated tests
  - 
    No tests needed
  ğŸ“¸ Screenshots / Videos
  Before After
  ... ...
  ğŸ“ Additional Information
  ref: https://help.aliyun.com/zh/model-studio/newly-released-models
  ref: https://bailian.console.aliyun.com/cn-beijing/?tab=doc#/doc/?type=model&url=2987148
  Summary by Sourcery
  Extend Qwen image generation support to cover new text-to-image and image-to-image models while routing legacy models via dedicated text2image/image2image endpoints and defaulting other models to the multimodal-generation API.
  New Features:
  - Add model metadata and configuration for new Qwen image models including Z-Image Turbo, Qwen Image Edit Max/Plus, Qwen Image Max/Plus, and Wanxiang 2.5/2.6 variants.
  - Introduce explicit handling of legacy text-to-image and image-to-image Qwen models via separate async text2image and image2image endpoints.
  Enhancements:
  - Update the Qwen image creation flow to prefer the multimodal-generation endpoint for newer models and improve error messaging and logging across image workflows.
  - Reformat select Qwen chat model descriptions for consistency without changing behavior.
  Tests:
  - Adjust Qwen image creation tests to align with the new multimodal-generation behavior and removed strict input validation on qwen-image-edit-specific image URL requirements.
ReleaseNotesUrl: https://github.com/lobehub/lobehub/releases/tag/v2.1.31
Documentations:
- DocumentLabel: Docs
  DocumentUrl: https://lobehub.com/docs/usage/start
ManifestType: defaultLocale
ManifestVersion: 1.12.0
