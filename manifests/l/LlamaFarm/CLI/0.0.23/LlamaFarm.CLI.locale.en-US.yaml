# Created with WinGet Releaser using komac v2.14.0
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: LlamaFarm.CLI
PackageVersion: 0.0.23
PackageLocale: en-US
Publisher: LlamaFarm
PublisherUrl: https://llamafarm.dev/
PublisherSupportUrl: https://github.com/llama-farm/llamafarm/issues
PackageName: LlamaFarm CLI
PackageUrl: https://github.com/llama-farm/llamafarm
License: Apache-2.0
LicenseUrl: https://github.com/llama-farm/llamafarm/blob/HEAD/LICENSE
Copyright: Copyright (c) LlamaFarm
ShortDescription: The Complete AI Development Framework - From Local Prototypes to Production Systems
Description: |
  LlamaFarm is a comprehensive, modular AI framework that gives you complete control over your AI stack. Build powerful AI applications locally with production-ready components including RAG systems, vector databases, model management, prompt engineering, and fine-tuning - all designed to work seamlessly together or independently.

  Features:
  - Local-First Development - Build and test entirely on your machine
  - Production-Ready Components - Battle-tested modules that scale from laptop to cluster
  - Strategy-Based Configuration - Smart defaults with infinite customization
  - Deploy Anywhere - Same code runs locally, on-premises, or in any cloud
  - Multi-Provider Support - Use cloud LLM providers or run your own models locally
  - Complete RAG Pipeline - Document processing, embedding, and retrieval
Moniker: lf
Tags:
- ai
- aiproject
- edge
- edge-computing
- finetuning-llms
- llama3
- llama4
- models
- prompt-engineering
- rag
ReleaseNotes: |-
  0.0.23 (2025-12-20)
  Bug Fixes
  - runtime: broken pipe due to bad logging (02969d0)
ReleaseNotesUrl: https://github.com/llama-farm/llamafarm/releases/tag/v0.0.23
ManifestType: defaultLocale
ManifestVersion: 1.10.0
