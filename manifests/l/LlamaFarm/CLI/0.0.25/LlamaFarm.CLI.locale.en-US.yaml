# Created with WinGet Releaser using komac v2.14.0
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: LlamaFarm.CLI
PackageVersion: 0.0.25
PackageLocale: en-US
Publisher: LlamaFarm
PublisherUrl: https://llamafarm.dev/
PublisherSupportUrl: https://github.com/llama-farm/llamafarm/issues
PackageName: LlamaFarm CLI
PackageUrl: https://github.com/llama-farm/llamafarm
License: Apache-2.0
LicenseUrl: https://github.com/llama-farm/llamafarm/blob/HEAD/LICENSE
Copyright: Copyright (c) LlamaFarm
ShortDescription: The Complete AI Development Framework - From Local Prototypes to Production Systems
Description: |
  LlamaFarm is a comprehensive, modular AI framework that gives you complete control over your AI stack. Build powerful AI applications locally with production-ready components including RAG systems, vector databases, model management, prompt engineering, and fine-tuning - all designed to work seamlessly together or independently.

  Features:
  - Local-First Development - Build and test entirely on your machine
  - Production-Ready Components - Battle-tested modules that scale from laptop to cluster
  - Strategy-Based Configuration - Smart defaults with infinite customization
  - Deploy Anywhere - Same code runs locally, on-premises, or in any cloud
  - Multi-Provider Support - Use cloud LLM providers or run your own models locally
  - Complete RAG Pipeline - Document processing, embedding, and retrieval
Moniker: lf
Tags:
- ai
- aiproject
- edge
- edge-computing
- finetuning-llms
- llama3
- llama4
- models
- prompt-engineering
- rag
ReleaseNotes: |-
  0.0.25 (2026-01-14)
  Features
  - auto-process files on dataset upload (#661) (e08d762)
  - designer: add all api calls to dev tools (#680) (d36f6ff)
  - designer: add sse streaming for embedding model downloads (#655) (b2ffbd0)
  - designer: test space to include anomaly and classifier tests +other updates (#657) (fc94563)
  - runtime: support for native tool calling (#636) (f99f305)
  Bug Fixes
  - cli: config validation errors output (#673) (6d92f43)
  - install/run failures on windows w/ nvidia (#665) (29f3242)
  - rag: remove parser fallback (#642) (7037219)
  - runtime: move deps to main and enable offline GGUF loading (#670) (1d9de0c)
  Miscellaneous Chores
  - release 0.0.25 (74dea58)
  This PR was generated with Release Please. See documentation.
  Desktop App Downloads
  macOS
  Download for Apple Silicon (M1+) or Intel Macs:
  - Apple Silicon (arm64): LlamaFarm-desktop-app-mac-arm64.dmg or .zip
  - Intel (x64): LlamaFarm-desktop-app-mac-x64.dmg or .zip
  Installation:
  1. Download the DMG or ZIP file for your architecture
  2. Open the DMG and drag LlamaFarm to Applications (or extract the ZIP)
  3. Launch the app (it's signed and notarized, so it will open normally)
  4. The app will auto-install the CLI and start services
  Linux
  Download the appropriate package for your Linux distribution:
  - AppImage (Universal): LlamaFarm-desktop-app-linux.AppImage
  - Debian/Ubuntu: LlamaFarm-desktop-app-linux.deb
  Installation:
  # AppImage (works on all distributions)
  chmod +x LlamaFarm-desktop-app-linux.AppImage
  ./LlamaFarm-desktop-app-linux.AppImage
  # Debian/Ubuntu
  sudo dpkg -i LlamaFarm-desktop-app-linux.deb
  Windows
  Download the Windows installer:
  - Windows Installer: LlamaFarm-desktop-app-windows.exe
  Installation:
  1. Download the installer
  2. Run the installer (it will install to your user directory)
  3. Launch LlamaFarm from the Start Menu
  4. The app will auto-install the CLI and start services
  Auto-Updates
  Once installed, the app will automatically check for updates and prompt you to install them.
ReleaseNotesUrl: https://github.com/llama-farm/llamafarm/releases/tag/v0.0.25
ManifestType: defaultLocale
ManifestVersion: 1.10.0
