# Created with WinGet Releaser using komac v2.14.0
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: LlamaFarm.CLI
PackageVersion: 0.0.20
PackageLocale: en-US
Publisher: LlamaFarm
PublisherUrl: https://llamafarm.dev/
PublisherSupportUrl: https://github.com/llama-farm/llamafarm/issues
PackageName: LlamaFarm CLI
PackageUrl: https://github.com/llama-farm/llamafarm
License: Apache-2.0
LicenseUrl: https://github.com/llama-farm/llamafarm/blob/HEAD/LICENSE
Copyright: Copyright (c) LlamaFarm
ShortDescription: The Complete AI Development Framework - From Local Prototypes to Production Systems
Description: |
  LlamaFarm is a comprehensive, modular AI framework that gives you complete control over your AI stack. Build powerful AI applications locally with production-ready components including RAG systems, vector databases, model management, prompt engineering, and fine-tuning - all designed to work seamlessly together or independently.

  Features:
  - Local-First Development - Build and test entirely on your machine
  - Production-Ready Components - Battle-tested modules that scale from laptop to cluster
  - Strategy-Based Configuration - Smart defaults with infinite customization
  - Deploy Anywhere - Same code runs locally, on-premises, or in any cloud
  - Multi-Provider Support - Use cloud LLM providers or run your own models locally
  - Complete RAG Pipeline - Document processing, embedding, and retrieval
Moniker: lf
Tags:
- ai
- aiproject
- edge
- edge-computing
- finetuning-llms
- llama3
- llama4
- models
- prompt-engineering
- rag
ReleaseNotes: |-
  0.0.20 (2025-12-10)
  Features
  - cli: add auto-start service flag (#335) (6f18bde)
  - designer: more gguf options for download (#546) (7f67d97)
  - rag: list rag database documents (#547) (b99eebc)
  - rag: report rag stats (#543) (d6e2837)
  - remove db chunks on file deletion (#549) (21bd24b)
  - server: start and stop data process (#489) (1448b1a)
  Bug Fixes
  - app: first run startup failures (#567) (f70436e)
  - cli: expand ~ before path resolution (#563) (a862716)
  - cli: ignore python specific env vars (#564) (ee4f9af)
  - cli: improve process manager locking (#573) (863a85a)
  - cli: resolve upgrade hang caused by process stop deadlock (#566) (5466de3)
  - designer: wrong version showing (#552) (c10335f)
  - rag: prevent storage of failed vectors (#571) (4aceb2e)
  - show modal error dialog (#570) (70864f1)
  Miscellaneous Chores
  - release 0.0.20 (b7538ed)
ReleaseNotesUrl: https://github.com/llama-farm/llamafarm/releases/tag/v0.0.20
ManifestType: defaultLocale
ManifestVersion: 1.10.0
