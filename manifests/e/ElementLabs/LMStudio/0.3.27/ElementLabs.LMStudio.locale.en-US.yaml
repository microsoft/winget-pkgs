# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: ElementLabs.LMStudio
PackageVersion: 0.3.27
PackageLocale: en-US
Publisher: LM Studio
PublisherUrl: https://lmstudio.ai/
Author: Element Labs, Inc.
PackageName: LM Studio
PackageUrl: https://lmstudio.ai/
License: Freeware
LicenseUrl: https://lmstudio.ai/terms
Copyright: Â© LM Studio 2023 - 2025
CopyrightUrl: https://lmstudio.ai/terms
ShortDescription: Discover, download, and run local LLMs
Description: LM Studio is an easy to use desktop app for experimenting with local and open-source Large Language Models (LLMs). The LM Studio cross platform desktop app allows you to download and run any ggml-compatible model from Hugging Face, and provides a simple yet powerful model configuration and inferencing UI. The app leverages your GPU when possible.
Tags:
- ai
- chatbot
- deepseek
- gemma
- kimi
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  0.3.27 - Release Notes
  Build 4
  - Improved VRAM usage estimation, especially when flash attention is enabled
  Build 3
  - Setting to control whether to open the downloads panel after starting a model download (default: false)
  - Update CLI (lms) output colors to have better contrast in light mode
  - Fix a bug where copy buttons would sometimes not appear on conversation code blocks
  Build 2
  - New: Find in Chat (Cmd/Ctrl+F) and Search All Chats (Cmd/Ctrl+Shift+F).
  - New: Sort chats sidebar by date updated, date created, or token count
  - Model resources estimation will now work for vision models
  - Added model resources estimation to the CLI. You can now run lms load --estimate-only <model-name> to preview a model's estimated memory requirements before loading
  - While using lms chat, you can now use Ctrl^C to interrupt ongoing predictions
  Build 1
  - Additional model quantization files downloaded after the main model will now be properly nested under it
  - Improved memory usage estimation used for model loading guardrails.
    - Now memory estimation will take into account selected context lengths.
  - lms ps --json now reports model generation status and the number of queued prediction requests
ReleaseNotesUrl: https://lmstudio.ai/blog
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://lmstudio.ai/docs/welcome
ManifestType: defaultLocale
ManifestVersion: 1.10.0
