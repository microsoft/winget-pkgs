# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.12.0.schema.json

PackageIdentifier: ElementLabs.LMStudio
PackageVersion: 0.4.1+1
PackageLocale: en-US
Publisher: LM Studio
PublisherUrl: https://lmstudio.ai/
Author: Element Labs, Inc.
PackageName: LM Studio
PackageUrl: https://lmstudio.ai/
License: Freeware
LicenseUrl: https://lmstudio.ai/terms
Copyright: Â© LM Studio 2023 - 2026
CopyrightUrl: https://lmstudio.ai/terms
ShortDescription: Discover, download, and run local LLMs
Description: LM Studio is an easy to use desktop app for experimenting with local and open-source Large Language Models (LLMs). The LM Studio cross platform desktop app allows you to download and run any ggml-compatible model from Hugging Face, and provides a simple yet powerful model configuration and inferencing UI. The app leverages your GPU when possible.
Tags:
- ai
- chatbot
- deepseek
- gemma
- kimi
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  - New: Anthropic API compatibility endpoint: /v1/messages
    - Use Claude Code with LM Studio ðŸ‘¾
  - Added a new "Deep Dark" theme option for the UI
  - Added --parallel <N> flag to lms load command to allow loading a model with specified number of max parallel predictions
  - [Mac] Fixed "kernel_mul_mv_bf16_f32_4 was not found in the library" bug on model load
  - Fixed a bug where lms chat cannot use non-ASCII characters
  - Fixed a bug where UI will sometimes crash after a loaded model is removed
  - Fixed a bug where LM Studio sometimes creates multiple backups for model index cache
  - Fixed responsive handling of chat terminal icons
  - Fixed a bug causing UI to crash with "Cannot read properties of null"
  - Fixed a bug to persist expanded config section choices across sessions
  - Fixed a bug in splitting and collapsing panes, and replacing chat tabs
  - Fixed a bug where Codex would encounter errors when unsupported tools were passed to LM Studio
  - Fixed a bug where the model loader would sometimes not populate with correct override model default values
  - Fixed a bug where input_tokens and cached_tokens were sometimes reported incorrectly in /v1/responses API
  - Fixed edge cases in which Developer Mode wouldn't turn on automatically when updating 0.3 -> 0.4
ReleaseNotesUrl: https://lmstudio.ai/blog
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://lmstudio.ai/docs/welcome
ManifestType: defaultLocale
ManifestVersion: 1.12.0
