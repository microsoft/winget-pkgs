# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.12.0.schema.json

PackageIdentifier: ElementLabs.LMStudio
PackageVersion: 0.4.6+1
PackageLocale: en-US
Publisher: LM Studio
PublisherUrl: https://lmstudio.ai/
Author: Element Labs, Inc.
PackageName: LM Studio
PackageUrl: https://lmstudio.ai/
License: Freeware
LicenseUrl: https://lmstudio.ai/terms
Copyright: Â© LM Studio 2023 - 2026
CopyrightUrl: https://lmstudio.ai/terms
ShortDescription: Discover, download, and run local LLMs
Description: LM Studio is an easy to use desktop app for experimenting with local and open-source Large Language Models (LLMs). The LM Studio cross platform desktop app allows you to download and run any ggml-compatible model from Hugging Face, and provides a simple yet powerful model configuration and inferencing UI. The app leverages your GPU when possible.
Tags:
- ai
- chatbot
- deepseek
- gemma
- kimi
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  - âœ¨ðŸŽ‰ Introducing LM Link
    - Connect to remote instances of LM Studio, load your models, and use them as if they were local.
    - End-to-end encrypted. Launching in partnership with Tailscale.
  - Fixed a bug where auto update will sometimes not work due to failing to exit before updater runs.
    - This fix only applies, when updating to the next version. That is, you might still encounter issues as you are updating to 0.4.6+1.
  - Fixed Qwen3.5 RAG jinja rendering bug: "No user query found in messages"
  - Updated go version to 0.25.7 for LM Link.
  - [DGX Spark] Enable Direct I/O to improve model load latency
    - Requires llama.cpp engine 2.5.1 or greater.
ReleaseNotesUrl: https://lmstudio.ai/blog
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://lmstudio.ai/docs/welcome
ManifestType: defaultLocale
ManifestVersion: 1.12.0
