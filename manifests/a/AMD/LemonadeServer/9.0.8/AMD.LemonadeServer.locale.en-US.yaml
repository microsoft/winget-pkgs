# Created with YamlCreate.ps1 v2.5.0 $debug=NVS1.CRLF.7-5-4.Win32NT
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: AMD.LemonadeServer
PackageVersion: 9.0.8
PackageLocale: en-US
Publisher: AMD
PublisherUrl: https://lemonade-server.ai/
PublisherSupportUrl: https://github.com/lemonade-sdk/lemonade/issues
# PrivacyUrl:
# Author:
PackageName: Lemonade Server
PackageUrl: https://lemonade-server.ai/
License: Apache-2.0
LicenseUrl: https://github.com/lemonade-sdk/lemonade/blob/HEAD/LICENSE
Copyright: Copyright (C) 2025 AMD
# CopyrightUrl:
ShortDescription: Refreshingly fast LLMs on GPUs and NPUs
Description: üçã Lemonade Server is a server interface that uses the standard Open AI API, allowing applications to integrate with local LLMs. This means that you can easily replace cloud-based LLMs with private and free LLMs that run locally on your own PC's NPU and GPU.
# Moniker:
Tags:
- ai
- chatbot
- large-language-model
- llm
- local-llm
ReleaseNotes: |-
  What's Changed
  - Set the FLM server host name by @jeremyfowers in #654
  - Allow overriding llama-server bin path through the environment by @bitgamma in #651
  - Adding CPU Backend Support to LlamaCPP Server for Lemonade CPP by @siavashhub in #627
  - Debate Arena v2, and multi-model improvements by @jeremyfowers in #659
  New Contributors
  - @bitgamma made their first contribution in #651
  Full Changelog: https://github.com/lemonade-sdk/lemonade/compare/v9.0.7...v9.0.8
ReleaseNotesUrl: https://github.com/lemonade-sdk/lemonade/releases/tag/v9.0.8
# PurchaseUrl:
# InstallationNotes:
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://lemonade-server.ai/docs/
ManifestType: defaultLocale
ManifestVersion: 1.10.0
