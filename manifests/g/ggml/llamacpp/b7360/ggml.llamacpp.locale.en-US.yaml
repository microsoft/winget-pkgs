# Created with komac v2.11.2
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.9.0.schema.json

PackageIdentifier: ggml.llamacpp
PackageVersion: b7360
PackageLocale: en-US
Publisher: ggml
PublisherUrl: https://github.com/ggml-org
PublisherSupportUrl: https://github.com/ggml-org/llama.cpp/issues
PackageName: llama.cpp
PackageUrl: https://github.com/ggml-org/llama.cpp
License: MIT
LicenseUrl: https://github.com/ggml-org/llama.cpp/blob/HEAD/LICENSE
ShortDescription: LLM inference in C/C++
Tags:
- ggml
- llama
ReleaseNotes: |-
  Warning
  Release Format Update: Linux releases will soon use .tar.gz archives instead of .zip. Please make the necessary changes to your deployment scripts.
  SOLVE_TRI extension to more dimensions (#17793)
  - Extended TRI
  - Fix whitespace
  - chore: update webui build output
  - Just use cuBLAS for everything...
  - Merge both versions
  - Remove incorrect imports causing failures for CI
  - Still failing... remove all direct cublas imports and rely on common imports from "common.cuh"
  - Defines for hipBlas
  - Aaaand MUSA defines...
  - I hate this job...
  - Stupid typo...
  - Update ggml/src/ggml-cuda/solve_tri.cu
  Co-authored-by: Johannes Gäßler johannesg@5d6.de
  Co-authored-by: Johannes Gäßler johannesg@5d6.de
  macOS/iOS:
  - macOS Apple Silicon (arm64)
  - macOS Intel (x64)
  - iOS XCFramework
  Linux:
  - Ubuntu x64 (CPU)
  - Ubuntu x64 (Vulkan)
  - Ubuntu s390x (CPU)
  Windows:
  - Windows x64 (CPU)
  - Windows arm64 (CPU)
  - Windows x64 (CUDA 12)
  - Windows x64 (CUDA 13)
  - Windows x64 (Vulkan)
  - Windows x64 (SYCL)
  - Windows x64 (HIP)
ReleaseNotesUrl: https://github.com/ggml-org/llama.cpp/releases/tag/b7360
Documentations:
- DocumentLabel: Wiki
  DocumentUrl: https://github.com/ggml-org/llama.cpp/wiki
ManifestType: defaultLocale
ManifestVersion: 1.9.0
