# Created with komac v2.11.2
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.9.0.schema.json

PackageIdentifier: ggml.llamacpp
PackageVersion: b7898
PackageLocale: en-US
Publisher: ggml
PublisherUrl: https://github.com/ggml-org
PublisherSupportUrl: https://github.com/ggml-org/llama.cpp/issues
PackageName: llama.cpp
PackageUrl: https://github.com/ggml-org/llama.cpp
License: MIT
LicenseUrl: https://github.com/ggml-org/llama.cpp/blob/HEAD/LICENSE
ShortDescription: LLM inference in C/C++
Tags:
- ggml
- llama
ReleaseNotes: |-
  ggml-hexagon: flash-attention and reduce-sum optimizations (#19141)
  - wip
  - ggml-hexagon: add vectorized dot product function for FP32 and FP16 accumulation
  - ggml-hexagon: optimize dot product functions for FP16 and FP32 with new vectorized implementations
  - wip
  - ggml-hexagon: optimize hvx_vec_dump_f32_n and hvx_vec_reduce_sum_qf32x2 functions for improved performance
  - ggml-hexagon: refactor dot product functions to use a common loading function for improved readability
  - optimize vector dot product functions to use unified reduction for improved performance
  - wip
  - ggml-hexagon: add vectorized dot product function for FP32 and FP16 accumulation
  - ggml-hexagon: optimize dot product functions for FP16 and FP32 with new vectorized implementations
  - wip
  - ggml-hexagon: optimize hvx_vec_dump_f32_n and hvx_vec_reduce_sum_qf32x2 functions for improved performance
  - ggml-hexagon: refactor dot product functions to use a common loading function for improved readability
  - optimize vector dot product functions to use unified reduction for improved performance
  - hexagon: optimize reduce-sum for v75+
  - hexagon: always keep row_sums in sf/fp32
  - ggml-hexagon: enhance directory checks for HEXAGON_SDK_ROOT and HEXAGON_TOOLS_ROOT
  - fix compiling error after rebase
  Co-authored-by: Max Krasnyansky maxk@qti.qualcomm.com
  macOS/iOS:
  - macOS Apple Silicon (arm64)
  - macOS Intel (x64)
  - iOS XCFramework
  Linux:
  - Ubuntu x64 (CPU)
  - Ubuntu x64 (Vulkan)
  - Ubuntu s390x (CPU)
  Windows:
  - Windows x64 (CPU)
  - Windows arm64 (CPU)
  - Windows x64 (CUDA 12) - CUDA 12.4 DLLs
  - Windows x64 (CUDA 13) - CUDA 13.1 DLLs
  - Windows x64 (Vulkan)
  - Windows x64 (SYCL)
  - Windows x64 (HIP)
  openEuler:
  - openEuler x86 (310p)
  - openEuler x86 (910b, ACL Graph)
  - openEuler aarch64 (310p)
  - openEuler aarch64 (910b, ACL Graph)
ReleaseNotesUrl: https://github.com/ggml-org/llama.cpp/releases/tag/b7898
Documentations:
- DocumentLabel: Wiki
  DocumentUrl: https://github.com/ggml-org/llama.cpp/wiki
ManifestType: defaultLocale
ManifestVersion: 1.9.0
