# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: Jan.Jan
PackageVersion: 0.6.6
PackageLocale: en-US
Publisher: Jan
PublisherUrl: https://jan.ai/
PublisherSupportUrl: https://github.com/menloresearch/jan/issues
Author: Homebrew Computer Company
PackageName: Jan
PackageUrl: https://jan.ai/
License: AGPL-3.0
LicenseUrl: https://github.com/menloresearch/jan/blob/HEAD/LICENSE
Copyright: Copyright ¬© 2024 Jan
ShortDescription: Turn your computer into an AI computer
Description: Run LLMs like Mistral or Llama2 locally and offline on your computer, or connect to remote AI APIs like OpenAI‚Äôs GPT-4 or Groq.
Tags:
- ai
- large-language-model
- llama
- llm
- mistral
ReleaseNotes: |-
  Changes
  - Add RunEvent::Exit event to tauri to handle macos context menu exit @qnixsynapse (#6005)
  - fix: remove auto refresh model custom provider @urmauur (#6002)
  - fix: generate response button disappear on tool call @louis-menlo (#5988)
  - fix: title tooltip MCP edit json @urmauur (#5987)
  - fix: download progress missing when left panel scrollable @urmauur (#5984)
  - fix: failed provider models list due to broken cortex import @louis-menlo (#5983)
  - Sync Release/v0.6.6 into dev @louis-menlo (#5973)
  - fix: use direct process termination instead of console events on Windows @qnixsynapse (#5972)
  - fix: rename thread dialog shows previous thread @urmauur (#5963)
  - chore: allow all HTTPS image sources in img-src directive @Minh141120 (#5970)
  - feat: Enhance port selection with availability check @qnixsynapse (#5966)
  - fix: csp including img.shields.io and cdn-uploads.huggingface.co in img-src directive @Minh141120 (#5967)
  - ci: tolerate artifact upload @Minh141120 (#5969)
  - fix: assistant with last used and fix metadata @urmauur (#5955)
  - fix: search models result in hub should be sorted by weight @louis-menlo (#5954)
  - fix: factory reset fail with access denied error @louis-menlo (#5952)
  - fix: set autoUnload in onLoad() @qnixsynapse (#5956)
  - fix: update edge case experimental feature MCP @urmauur (#5951)
  - fix: correctly apply auto_unload setting from config @qnixsynapse (#5953)
  - fix: Prevent race condition with auto-unload during rapid model loading @qnixsynapse (#5947)
  - chore: uninstall when upgrading windows installer @Minh141120 (#5945)
  - fix: openrouter unselect itself @louis-menlo (#5943)
  - fix: tool approval params scrollable @urmauur (#5941)
  - fix: migrate app settings to the new version @louis-menlo (#5936)
  - fix: Remove sInfo from activeSessions before unloading @qnixsynapse (#5938)
  - fix: update default GPU toggle, and simplify state @urmauur (#5937)
  - chore: revert back to passive mode on windows installer @Minh141120 (#5934)
  - fix: update ui version_backend, mem usage hardware @urmauur (#5932)
  - fix: Frontend updates when llama.cpp backend auto-downloads @qnixsynapse (#5926)
  - fix: calculation memory on hardware and system monitor @urmauur (#5922)
  - fix: persist model capabilities refresh app @urmauur (#5918)
  - fix: validate name assistant and improve area clickable @urmauur (#5920)
  - fix: Allow N-GPU Layers (NGL) to be set to 0 in llama.cpp @qnixsynapse (#5907)
  - fix: models hub should show latest data only @louis-menlo (#5925)
  - fix: Persist 'Auto-Unload Old Models' setting in llama.cpp @qnixsynapse (#5906)
  - feat: Enhance Llama.cpp backend management with persistence @qnixsynapse (#5886)
  - Chore cua mac runner @hiento09 (#5888)
  - fix: provider settings should be refreshed on page load @louis-menlo (#5887)
  - üêõfix: get system info and system usage @urmauur (#5884)
  - fix: gpu detected from backend version @urmauur (#5882)
  - fix: bring back HF repo ID search in Hub @louis-menlo (#5880)
  - chore: revert app artifact name for macos linux and windows builds @Minh141120 (#5878)
  - feat: add support for querying available backend devices @qnixsynapse (#5877)
  - fix: llama.cpp backend shows blank list sometime @louis-menlo (#5876)
  - ci: rename app github artifact on windows and linux build @Minh141120 (#5875)
  - ci: autoqa github artifact @Minh141120 (#5873)
  - fix: jan should have a general assistant instruction @louis-menlo (#5872)
  - fix: tmp download file should be removed on cancel @louis-menlo (#5849)
  - üêõfix: remove sampling parameters from llamacpp extension @urmauur (#5871)
  - üêõfix: update vulkan active syntax @urmauur (#5869)
  - fix: app should not show manually deleted models @louis-menlo (#5868)
  - feat: migrate cortex models to llamacpp extension @louis-menlo (#5838)
  - fix: charmap encoding @Minh141120 (#5865)
  - fix: HuggingFace provider should be non-deletable @louis-menlo (#5856)
  - fix: gemini tool call support - version bump @louis-menlo (#5848)
  - Fix: engine unable to find dlls on when running on Windows @qnixsynapse (#5863)
  - chore: update build appimage script @Minh141120 (#5866)
  - ‚ú®enhancement: dialog model error trigger from provider screen @urmauur (#5858)
  - fix: support load model configurations @urmauur (#5843)
  - fix: delete all thread should not include fav @urmauur (#5864)
  - Chore: enrich autoqa log @hiento09 (#5862)
  - refactor: Improve Llama.cpp backend management and auto-update @qnixsynapse (#5845)
  - fix: autoqa prompt template @Minh141120 (#5854)
  - feat: add vcruntime for windows installer @Minh141120 (#5852)
  - ‚ú®enhancement: auto focus always allow action from tool approval dialog and add req parameters @urmauur (#5836)
  - enhancement: better error page component @urmauur (#5834)
  - chore: sync make build with dev @Minh141120 (#5847)
  - refactor: standardize build process and remove build-tauri target @Minh141120 (#5846)
  - fix: custom tauri nsis template CheckIfAppIsRunning macro @Minh141120 (#5840)
  - fix: update @taur-apps/cli to newest verison to fix appimage download @Minh141120 (#5839)
  - fix: prevent terminal window from opening on model load on WindowsOS @qnixsynapse (#5837)
  - feat: add claude-4 @louis-menlo (#5829)
  - feat: support per-model overrides in llama.cpp load() @qnixsynapse (#5820)
  - fix: llama.cpp integration model load and chat experience @louis-menlo (#5823)
  - test: deprecate webdriver test in favor of auto qa using CUA @louis-menlo (#5825)
  - Revert "chore(deps): update rand requirement from 0.8 to 0.9 in /src-tauri" @louis-menlo (#5824)
  - fix: Legacy threads show on top of new threads (#5696) @louis-menlo (#5810)
  - fix: llama.cpp backend download on windows @louis-menlo (#5813)
  - fix: dependabot should just update security patch @louis-menlo (#5814)
  - chore(deps): update rand requirement from 0.8 to 0.9 in /src-tauri @dependabot (#5399)
  - docs: Add Instruction for Toggling Experimental Features Before Toggling MCP Servers @bytrangle (#5771)
  - chore(deps): bump @radix-ui/react-hover-card from 1.1.11 to 1.1.14 @dependabot (#5603)
  - Fix autoqa lib dependencies @hiento09 (#5812)
  - refactor: simplify proxy settings by removing unused SSL verification options @louis-menlo (#5809)
  - feat: Add Hugging Face as a provider @gary149 (#5808)
  - fix: Improve stream error handling and parsing @qnixsynapse (#5807)
  - feat: add autoqa @hiento09 (#5779)
  - set line number userSelect to none so that code can be copied without line number @ethanova (#5782)
  - feat: add model load error handling to improve UX @louis-menlo (#5802)
  - fix: Add --reasoning-format none to support rendering of reasoning content @qnixsynapse (#5803)
  - feat: proxy support for the new downloader @louis-menlo (#5795)
  - Sync release/0.6.5 into dev to start new development cycle @louis-menlo (#5801)
  - refactor: move thinking toggle to runtime settings for dynamic control @qnixsynapse (#5800)
  - test: deprecate webdriver test in favor of auto qa using CUA @louis-menlo (#5797)
  - Documentation Updates for v0.6.5 @ramonpzg (#5799)
  Contributor
  @Minh141120, @bytrangle, @dependabot, @dependabot[bot], @ethanova, @gary149, @hiento09, @louis-menlo, @qnixsynapse, @ramonpzg and @urmauur
ReleaseNotesUrl: https://github.com/menloresearch/jan/releases/tag/v0.6.6
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://jan.ai/docs
ManifestType: defaultLocale
ManifestVersion: 1.10.0
