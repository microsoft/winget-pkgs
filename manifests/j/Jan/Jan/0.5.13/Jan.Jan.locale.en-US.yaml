# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.9.0.schema.json

PackageIdentifier: Jan.Jan
PackageVersion: 0.5.13
PackageLocale: en-US
Publisher: Jan
PublisherUrl: https://jan.ai/
PublisherSupportUrl: https://github.com/janhq/jan/issues
Author: Homebrew Computer Company
PackageName: Jan
PackageUrl: https://github.com/janhq/jan
License: AGPL-3.0
LicenseUrl: https://github.com/janhq/jan/blob/HEAD/LICENSE
Copyright: Copyright ¬© 2024 Jan
ShortDescription: Turn your computer into an AI computer
Description: Run LLMs like Mistral or Llama2 locally and offline on your computer, or connect to remote AI APIs like OpenAI‚Äôs GPT-4 or Groq.
Tags:
- ai
- large-language-model
- llama
- llm
- mistral
ReleaseNotes: |-
  üêõ Fixes
  - fix: max_tokens revert back to 8192 automatically when creating a new thread @louis-jan (#4397)
  - fix: revert back product analytic with default opt-out @urmauur (#4394)
  - fix: send event opt out @urmauur (#4390)
  - fix: enable default opt in analytic @urmauur (#4387)
  - fix: should not disable Vulkan support option @louis-jan (#4382)
  - fix: bump llama.cpp engine hotfix version to address model load issue on some MacOS Intel machines @louis-jan (#4374)
  üß∞ Maintenance
  - chore: bump latest cortex release 1.0.8 @louis-jan (#4405)
  - chore: add cpu_threads settings in cortex extension @louis-jan (#4386)
  Contributor
  @louis-jan and @urmauur
ReleaseNotesUrl: https://github.com/janhq/jan/releases/tag/v0.5.13
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://jan.ai/docs
ManifestType: defaultLocale
ManifestVersion: 1.9.0
