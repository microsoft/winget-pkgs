# Created with YamlCreate.ps1 v2.4.1 Dumplings Mod $debug=QUSU.CRLF.7-4-2.Win32NT
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.6.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.1.40
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
# PrivacyUrl:
# Author:
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/main/LICENSE
Copyright: Copyright (c) Ollama
# CopyrightUrl:
ShortDescription: Get up and running with large language models locally.
# Description:
# Moniker:
Tags:
- llama
- llama2
- llm
- llms
- mistral
ReleaseNotes: |-
  New models
  - Codestral: Codestral is Mistral AIâ€™s first-ever code model designed for code generation tasks.
  - IBM Granite Code: now in 3B and 8B parameter sizes.
  - Deepseek V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model
  What's Changed
  - Fixed out of memory and incorrect token issues when running Codestral on 16GB Macs
  - Fixed issue where full-width characters (e.g. Japanese, Chinese, Russian) were deleted at end of the line when using ollama run
  New Examples
  - Use open-source models as coding assistant with Continue
  New Contributors
  - @zhewang1-intc made their first contribution in https://github.com/ollama/ollama/pull/3278
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.1.40
# PurchaseUrl:
# InstallationNotes:
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://github.com/ollama/ollama/tree/main/docs
ManifestType: defaultLocale
ManifestVersion: 1.6.0
