# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.7.1
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/main/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  What's Changed
  - Improved model memory management to allocate sufficient memory to prevent crashes when running multimodal models in certain situations
  - Enhanced memory estimation for models to prevent unintended memory offloading
  - ollama show will now show ... when data is truncated
  - Fixed crash that would occur with qwen2.5vl
  - Fixed crash on Nvidia's CUDA for llama3.2-vision
  - Support for Alibaba's Qwen 3 and Qwen 2 architectures in Ollama's new multimodal engine
  New Contributors
  - @ronxldwilson made their first contribution in https://github.com/ollama/ollama/pull/10763
  - @DarkCaster made their first contribution in https://github.com/ollama/ollama/pull/10779
  Full Changelog: https://github.com/ollama/ollama/compare/v0.7.0...v0.7.1-rc0
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.7.1
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://github.com/ollama/ollama/tree/main/docs
ManifestType: defaultLocale
ManifestVersion: 1.10.0
