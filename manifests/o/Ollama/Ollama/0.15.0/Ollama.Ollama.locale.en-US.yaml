# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.12.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.15.0
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/HEAD/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  New feature
  ollama launch command to use Ollama's models with Claude Code, Codex, OpenCode, and Droid without separate configuration.
  What's Changed
  - x/imagegen: add image edit capabilities by @jmorganca in https://github.com/ollama/ollama/pull/13846
  - cmd: handle Enter key pressed during model loading, render multiline better by @ParthSareen in https://github.com/ollama/ollama/pull/13839
  - x/imagegen: replace memory estimation with actual weight size by @jmorganca in https://github.com/ollama/ollama/pull/13848
  - cmd: ollama config command to help configure integrations to use Ollama by @ParthSareen in https://github.com/ollama/ollama/pull/13712
  - x/imagegen: respect stream=false in /api/generate by @jmorganca in https://github.com/ollama/ollama/pull/13853
  - cmd: ollama config fix droid model name configuration by @ParthSareen in https://github.com/ollama/ollama/pull/13856
  - model: add MLA absorption for glm4moelite by @jmorganca in https://github.com/ollama/ollama/pull/13810
  - x/imagegen: fix image editing support by @jmorganca in https://github.com/ollama/ollama/pull/13866
  - Revert "model: add MLA absorption for glm4moelite" by @jmorganca in https://github.com/ollama/ollama/pull/13869
  - Re-apply "model: add MLA absorption for glm4moelite" with fix by @jmorganca in https://github.com/ollama/ollama/pull/13870
  - cmd: rename ollama config to ollama launch by @ParthSareen in https://github.com/ollama/ollama/pull/13871
  - llama: fix fattn-tile shared memory overflow on sm_50/52 by @jmorganca in https://github.com/ollama/ollama/pull/13872
  - llama: fix CUDA release build issues by @jmorganca in https://github.com/ollama/ollama/pull/13874
  - Clean up the manifest and modelpath by @pdevine in https://github.com/ollama/ollama/pull/13807
  - x/imagegen: remove qwen_image and qwen_image_edit models by @jmorganca in https://github.com/ollama/ollama/pull/13827
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.15.0
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://docs.ollama.com/
ManifestType: defaultLocale
ManifestVersion: 1.12.0
