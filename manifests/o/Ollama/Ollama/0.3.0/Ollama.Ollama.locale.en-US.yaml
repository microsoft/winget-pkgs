# Created with YamlCreate.ps1 v2.4.1 Dumplings Mod $debug=QUSU.CRLF.7-4-3.Win32NT
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.6.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.3.0
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
# PrivacyUrl:
# Author:
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/main/LICENSE
Copyright: Copyright (c) Ollama
# CopyrightUrl:
ShortDescription: Get up and running with large language models locally.
# Description:
# Moniker:
Tags:
- llama
- llama2
- llm
- llms
- mistral
ReleaseNotes: |-
  Tool support
  Ollama now supports tool calling with popular models such as Llama 3.1. This enables a model to answer a given prompt using tool(s) it knows about, making it possible for models to perform more complex tasks or interact with the outside world.
  Example tools include:
  - Functions and APIs
  - Web browsing
  - Code interpreter
  - much more!
  https://github.com/user-attachments/assets/957ef0d6-e7b7-4168-8033-13b0fe5f7029
  To use tools, provide the tools field when using Ollama's Chat API:
  import ollama

  response = ollama.chat(
      model='llama3.1',
      messages=[{'role': 'user', 'content': 'What is the weather in Toronto?'}],

      # provide a weather checking tool to the model
      tools=[{
        'type': 'function',
        'function': {
          'name': 'get_current_weather',
          'description': 'Get the current weather for a city',
          'parameters': {
            'type': 'object',
            'properties': {
              'city': {
                'type': 'string',
                'description': 'The name of the city',
              },
            },
            'required': ['city'],
          },
        },
      },
    ],
  )

  print(response['message']['tool_calls'])
  More information:
  - Python example
  - JavaScript example
  - API Reference
  New models
  - Llama 3.1: a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes with support for tool calling.
  - Mistral Large 2: Mistral's new 123B flagship model that is significantly more capable in code generation, tool calling, mathematics, and reasoning with 128k context window and support for dozens of languages.
  - Firefunction v2: An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities.
  - Llama-3-Groq-Tool-Use: A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling.
  What's Changed
  - Fixed duplicate error message when running ollama create
  New Contributors
  - @lreed-mdsol made their first contribution in https://github.com/ollama/ollama/pull/5757
  - @ajhai made their first contribution in https://github.com/ollama/ollama/pull/5799
  Full Changelog: https://github.com/ollama/ollama/compare/v0.2.8...v0.3.0
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.3.0
# PurchaseUrl:
# InstallationNotes:
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://github.com/ollama/ollama/tree/main/docs
ManifestType: defaultLocale
ManifestVersion: 1.6.0
