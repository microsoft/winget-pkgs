# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.12.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.14.3
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/HEAD/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  New models
  - GLM-4.7-Flash: As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency.
  - LFM2.5-1.2B-Thinking: LFM2.5 is a new family of hybrid models designed for on-device deployment.
  What's Changed
  - Fixed issue where Ollama's macOS app would interrupt system shutdown
  - Fixed ollama create and ollama show commands for experimental models
  - The /api/generate API can now be used for image generation
  - Fixed minor issues in Nemotron-3-Nano tool parsing
  - Fixed issue where removing an image generation model would cause it to first load
  - Fixed issue where ollama rm would only stop the first model in the list if it were running
  Full Changelog: https://github.com/ollama/ollama/compare/v0.14.2...v0.14.3-rc2
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.14.3
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://docs.ollama.com/
ManifestType: defaultLocale
ManifestVersion: 1.12.0
