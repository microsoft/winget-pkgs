# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.12.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.17.1
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/HEAD/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  What's Changed
  - models: add nemotron architecture support by @jmorganca in https://github.com/ollama/ollama/pull/14356
  - Avoid Excessive MLX Memory Usage by @jessegross in https://github.com/ollama/ollama/pull/14341
  - ui: use capability-based detection for web search by @hoyyeva in https://github.com/ollama/ollama/pull/14336
  - mlxrunner: Fix duplicate log prefixes and reduce log noise by @jessegross in https://github.com/ollama/ollama/pull/14379
  - model: improvements to LFM2 architectures by @jmorganca in https://github.com/ollama/ollama/pull/14368
  - mlx: don't default to affine quantization for unquantized models by @jessegross in https://github.com/ollama/ollama/pull/14376
  - app: add upgrade configuration to settings page by @hoyyeva in https://github.com/ollama/ollama/pull/13512
  - update mlx-c bindings to 0.5.0 by @dhiltgen in https://github.com/ollama/ollama/pull/14380
  Full Changelog: https://github.com/ollama/ollama/compare/v0.17.0...v0.17.1
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.17.1
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://docs.ollama.com/
ManifestType: defaultLocale
ManifestVersion: 1.12.0
