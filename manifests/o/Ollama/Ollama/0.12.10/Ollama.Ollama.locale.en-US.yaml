# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.12.10
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/HEAD/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  ollama run now works with embedding models
  ollama run can now run embedding models to generate vector embeddings from text:
  ollama run embeddinggemma "Hello world"
  Content can also be provided to ollama run via standard input:
  echo "Hello world" | ollama run embeddinggemma
  What's Changed
  - Fixed errors when running qwen3-vl:235b and qwen3-vl:235b-instruct
  - Enable flash attention for Vulkan (currently needs to be built from source)
  - Add Vulkan memory detection for Intel GPU using DXGI+PDH
  - Ollama will now return tool call IDs from the /api/chat API
  - Fixed hanging due to CPU discovery
  - Ollama will now show login instructions when switching to a cloud model in interactive mode
  - Fix reading stale VRAM data
  - ollama run now works with embedding models
  New Contributors
  - @ryanycoleman made their first contribution in https://github.com/ollama/ollama/pull/11740
  - @Rajathbail made their first contribution in https://github.com/ollama/ollama/pull/12929
  - @virajwad made their first contribution in https://github.com/ollama/ollama/pull/12664
  - @AXYZdong made their first contribution in https://github.com/ollama/ollama/pull/8601
  Full Changelog: https://github.com/ollama/ollama/compare/v0.12.9...v0.12.10
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.12.10
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://docs.ollama.com/
ManifestType: defaultLocale
ManifestVersion: 1.10.0
