# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.9.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.6.4
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/main/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  What's Changed
  - /api/show will now include model capabilities such as vision
  - Fixed certain out-of-memory errors that would occur with parallel requests with Gemma 3
  - Gemma 3 will now properly understand and output certain multilingual characters
  - Fixed context shifting issues with models using the DeepSeek architecture
  - Fixed issues with 0.6.3 where Gemma 3's output quality would worsen after 512 or 1024 tokens
  - Added AMD RDNA4 support on Linux
  New Contributors
  - @saman-amd made their first contribution in https://github.com/ollama/ollama/pull/9878
  - @leandroBorgesFerreira made their first contribution in https://github.com/ollama/ollama/pull/10042
  - @Abyss-c0re made their first contribution in https://github.com/ollama/ollama/pull/9955
  - @uggrock made their first contribution in https://github.com/ollama/ollama/pull/9983
  - @IsAurora6 made their first contribution in https://github.com/ollama/ollama/pull/10057
  Full Changelog: https://github.com/ollama/ollama/compare/v0.6.3...v0.6.4
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.6.4
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://github.com/ollama/ollama/tree/main/docs
ManifestType: defaultLocale
ManifestVersion: 1.9.0
