# Created with YamlCreate.ps1 Dumplings Mod
# yaml-language-server: $schema=https://aka.ms/winget-manifest.defaultLocale.1.10.0.schema.json

PackageIdentifier: Ollama.Ollama
PackageVersion: 0.12.3
PackageLocale: en-US
Publisher: Ollama
PublisherUrl: https://ollama.com/
PublisherSupportUrl: https://github.com/ollama/ollama/issues
PackageName: Ollama
PackageUrl: https://ollama.com/
License: MIT
LicenseUrl: https://github.com/ollama/ollama/blob/HEAD/LICENSE
Copyright: Copyright (c) Ollama
ShortDescription: Get up and running with large language models locally.
Tags:
- ai
- chatbot
- deepseek
- large-language-model
- llama
- llm
- mistral
- qwen
ReleaseNotes: |-
  New models
  - DeepSeek-V3.1-Terminus: DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode. It delivers more stable & reliable outputs across benchmarks compared to the previous version:
    Run on Ollama's cloud:
    ollama run deepseek-v3.1:671b-cloud
    Run locally (requires 500GB+ of VRAM)
    ollama run deepseek-v3.1
  - Kimi-K2-Instruct-0905: Kimi K2-Instruct-0905 is the latest, most capable version of Kimi K2. It is a state-of-the-art mixture-of-experts (MoE) language model, featuring 32 billion activated parameters and a total of 1 trillion parameters.
    ollama run kimi-k2:1t-cloud
  What's Changed
  - Fixed issue where tool calls provided as stringified JSON would not be parsed correctly
  - ollama push will now provide a URL to follow to sign in
  - Fixed issues where qwen3-coder would output unicode characters incorrectly
  - Fix issue where loading a model with /load would crash
  New Contributors
  - @gr4ceG made their first contribution in https://github.com/ollama/ollama/pull/12385
  Full Changelog: https://github.com/ollama/ollama/compare/v0.12.2...v0.12.3
ReleaseNotesUrl: https://github.com/ollama/ollama/releases/tag/v0.12.3
Documentations:
- DocumentLabel: Documentation
  DocumentUrl: https://docs.ollama.com/
ManifestType: defaultLocale
ManifestVersion: 1.10.0
